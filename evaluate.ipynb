{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "example_inputs = [\n",
    "  (\"2024년 제22회 SW역량검증(TOPCIT) 정기평가의 평가일시는 언제인가요?\",\n",
    "   \"2024년 10월 12일 토요일 오전 9시 30분부터 12시까지입니다. 고사장 입실 완료 시간은 9시 10분입니다.\"),\n",
    "  (\"SW역량검증(TOPCIT) 정기평가에 단체 접수한 학생이 반드시 해야 할 절차는 무엇인가요?\",\n",
    "   \"(가) 구글 폼 신청과 (나) TOPCIT 홈페이지에서 신청자 정보등록을 모두 완료해야 시험에 응시할 수 있습니다.\"),\n",
    "  (\"SW역량검증(TOPCIT) 정기평가 단체접수의 등록기간은 언제인가요?\",\n",
    "   \"등록기간은 2024년 9월 12일(목)부터 9월 19일(목) 오후 3시까지입니다.\"),\n",
    "  (\"SW역량검증(TOPCIT) 정기평가 단체접수 대상자가 응시를 완료하면 어떤 혜택을 받을 수 있나요?\",\n",
    "   \"응시료 전액 지원과 함께 SW 마일리지 20점이 지급됩니다.\"),\n",
    "  (\"SW역량검증(TOPCIT) 정기평가에 응시하지 않은 학생은 어떻게 되나요?\",\n",
    "   \"신청 후 불응시한 학생은 SW 마일리지에서 10점이 차감됩니다.\"),\n",
    "  (\"SW역량검증(TOPCIT) 정기평가 단체접수 신청자는 어디서 시험을 보게 되나요?\",\n",
    "   \"단체접수용 시험장은 경북대학교 내 실습장으로 배정되며, 정확한 장소는 수험표 발급기간에 확인할 수 있습니다.\"),\n",
    "  (\"SW역량검증(TOPCIT) 정기평가 단체접수 신청은 어떻게 진행되나요?\",\n",
    "   \"구글 폼 링크를 통해 신청한 후, TOPCIT 홈페이지에서 신청자 정보를 등록해야 합니다.\"),\n",
    "  (\"SW역량검증(TOPCIT) 정기평가 관련 문의는 어디로 해야 하나요?\",\n",
    "   \"소프트웨어교육원(전화: 053-950-7670, 이메일: bk6722@knu.ac.kr)으로 문의할 수 있습니다.\"),\n",
    "]\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"TOPCIT\"\n",
    "\n",
    "# Storing inputs in a dataset lets us\n",
    "# run chains and LLMs over a shared set of examples.\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name, description=\"Questions and answers about TOPCIT\",\n",
    ")\n",
    "for input_prompt, output_answer in example_inputs:\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs={\"answer\": output_answer},\n",
    "        metadata={\"source\": \"공지사항\"},\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INDEX\n",
    "\n",
    "load_dotenv()\n",
    "# Load docs\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&wr_id=28223\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"id\": [\"bo_v_con\", \"bo_v_title\"]},\n",
    "        )\n",
    "    )\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = UpstageEmbeddings(\n",
    "    model=\"solar-embedding-1-large\"\n",
    ")\n",
    "\n",
    "# Embed and store in Chroma\n",
    "index_name = 'tax-index'\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "database = PineconeVectorStore.from_documents(splits, embeddings, index_name=index_name)\n",
    "\n",
    "# Index\n",
    "retriever=database.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain import hub\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"upstage-model\"):\n",
    "        self._retriever = retriever\n",
    "        self._client = ChatUpstage(model=model)\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        # 문서 검색 수행\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def invoke_llm(self, question, docs):\n",
    "        # Upstage LLM 호출\n",
    "        response = self._client.generate(  # 'chat' -> 'generate'\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"당신은 공지사항의 내용을 정확히 알려주는 직원입니다. \"\n",
    "                               \"다음 문서들을 사용하여 사용자 질문에 대한 간결한 답변을 작성하십시오.\\n\\n\"\n",
    "                               f\"## Docs\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # 응답 구조 확인 후 수정\n",
    "        # 예를 들어, Upstage의 응답이 choices 리스트를 포함하고 있을 수 있습니다.\n",
    "        answer = response['choices'][0]['message']['content']\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"contexts\": [str(doc) for doc in docs],\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rag_answer(example: dict):\n",
    "    \"\"\"답변만 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])  # 'input_question' -> 'question'\n",
    "    return {\"answer\": response[\"answer\"]}\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Context를 활용해서 hallucination을 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])  # 'input_question' -> 'question'\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain import hub\n",
    "\n",
    "# Grade prompt\n",
    "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")  # Upstage에서 제공하는 prompt\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Get question, ground truth answer, RAG chain answer\n",
    "    input_question = example.inputs.get(\"question\")\n",
    "    reference = example.outputs.get(\"answer\")\n",
    "    prediction = run.outputs.get(\"answer\")\n",
    "\n",
    "    # Upstage grader\n",
    "    llm = ChatUpstage(model=\"upstage-model\")  # Upstage LLM 모델 설정\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Run evaluator\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"correct_answer\": reference,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain import hub\n",
    "\n",
    "# Prompt\n",
    "grade_prompt_hallucinations = hub.pull(\"langchain-ai/rag-answer-hallucination\")  # Upstage에서 제공하는 프롬프트\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for generation hallucination\n",
    "    \"\"\"\n",
    "\n",
    "    # RAG inputs\n",
    "    input_question = example.inputs.get(\"question\")\n",
    "    contexts = run.outputs.get(\"contexts\")\n",
    "\n",
    "    # RAG answer\n",
    "    prediction = run.outputs.get(\"answer\")\n",
    "\n",
    "    # Upstage grader\n",
    "    llm = ChatUpstage(model=\"upstage-model\")  # Upstage LLM 모델 설정\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_hallucinations | llm\n",
    "\n",
    "    # Get score\n",
    "    score = answer_grader.invoke({\"documents\": contexts,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain import hub\n",
    "\n",
    "# Grade prompt\n",
    "grade_prompt_answer_helpfulness = hub.pull(\"langchain-ai/rag-answer-helpfulness\")  # Upstage에서 제공하는 프롬프트\n",
    "\n",
    "def answer_helpfulness_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer helpfulness\n",
    "    \"\"\"\n",
    "\n",
    "    # Get question and RAG chain answer\n",
    "    input_question = example.inputs.get(\"question\")\n",
    "    prediction = run.outputs.get(\"answer\")\n",
    "\n",
    "    # Upstage grader\n",
    "    llm = ChatUpstage(model=\"upstage-model\")  # Upstage LLM 모델 설정\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_answer_helpfulness | llm\n",
    "\n",
    "    # Run evaluator\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_helpfulness_score\", \"score\": score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'topcit_evaluate-bf55e5b9' at:\n",
      "https://smith.langchain.com/o/410ab3fd-ee98-5d8d-81e6-22756766a30e/datasets/4088c41c-9f9d-48fc-830d-29620d55df41/compare?selectedSessions=fbbcb854-a053-4222-ba73-9eac039a75b4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b61691f2434bfc8ace7a9a92a63b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 04aca7aa-f920-4eb8-a1d4-3ba4733a6a1c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 04aca7aa-f920-4eb8-a1d4-3ba4733a6a1c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run facd7f2b-a0b9-4b20-b190-b694f3b60ebf: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 7af0916f-355a-45fe-9532-23fbb2e9af69: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run cc3a9d5b-8df1-446c-8d5f-7b73bdd01f8a: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run e9833c98-d021-4b71-bef9-d87dd809a24d: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run b3a3fdfc-6d0b-4407-b082-3d49d78c7de8: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 5a9d8e32-2fdb-470f-87f2-0334bd120c35: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 5fcd9816-dbd0-48c6-a305-f78fb56c8565: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\1871048977.py\", line 24, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run facd7f2b-a0b9-4b20-b190-b694f3b60ebf: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 7af0916f-355a-45fe-9532-23fbb2e9af69: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run cc3a9d5b-8df1-446c-8d5f-7b73bdd01f8a: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run e9833c98-d021-4b71-bef9-d87dd809a24d: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run b3a3fdfc-6d0b-4407-b082-3d49d78c7de8: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 5fcd9816-dbd0-48c6-a305-f78fb56c8565: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 5a9d8e32-2fdb-470f-87f2-0334bd120c35: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\3908644218.py\", line 23, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_evaluator, answer_helpfulness_evaluator],\n",
    "    experiment_prefix=\"topcit_evaluate\",\n",
    "    metadata={\"version\": \"topcit, upstage-model\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'topcit_evaluate-e8ef2af6' at:\n",
      "https://smith.langchain.com/o/410ab3fd-ee98-5d8d-81e6-22756766a30e/datasets/b04f3efe-fca1-4de9-9435-08b65c42b908/compare?selectedSessions=e270c46a-7fca-47ae-8321-2e7fa4d7f8a1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa55cac11d24009a2ca3ad8863ffe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: 'str' object has no attribute 'content'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating answer for question: SW역량검증(TOPCIT) 정기평가 단체접수의 등록기간은 언제인가요?\n",
      "Reference answer: 등록기간은 2024년 9월 12일(목)부터 9월 19일(목) 오후 3시까지입니다.\n",
      "Prediction: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run b04d9b2e-c2e0-4817-b48d-382a0a493a1c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating helpfulness for question: SW역량검증(TOPCIT) 정기평가 단체접수의 등록기간은 언제인가요?\n",
      "Prediction: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run b04d9b2e-c2e0-4817-b48d-382a0a493a1c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating answer for question: SW역량검증(TOPCIT) 정기평가 단체접수 신청은 어떻게 진행되나요?\n",
      "Reference answer: 구글 폼 링크를 통해 신청한 후, TOPCIT 홈페이지에서 신청자 정보를 등록해야 합니다.\n",
      "Prediction: None\n",
      "Evaluating answer for question: SW역량검증(TOPCIT) 정기평가에 단체 접수한 학생이 반드시 해야 할 절차는 무엇인가요?\n",
      "Reference answer: (가) 구글 폼 신청과 (나) TOPCIT 홈페이지에서 신청자 정보등록을 모두 완료해야 시험에 응시할 수 있습니다.\n",
      "Prediction: None\n",
      "Evaluating answer for question: 2024년 제22회 SW역량검증(TOPCIT) 정기평가의 평가일시는 언제인가요?\n",
      "Reference answer: 2024년 10월 12일 토요일 오전 9시 30분부터 12시까지입니다. 고사장 입실 완료 시간은 9시 10분입니다.\n",
      "Prediction: None\n",
      "Evaluating answer for question: SW역량검증(TOPCIT) 정기평가 단체접수 신청자는 어디서 시험을 보게 되나요?\n",
      "Reference answer: 단체접수용 시험장은 경북대학교 내 실습장으로 배정되며, 정확한 장소는 수험표 발급기간에 확인할 수 있습니다.\n",
      "Prediction: None\n",
      "Evaluating answer for question: SW역량검증(TOPCIT) 정기평가 관련 문의는 어디로 해야 하나요?\n",
      "Reference answer: 소프트웨어교육원(전화: 053-950-7670, 이메일: bk6722@knu.ac.kr)으로 문의할 수 있습니다.\n",
      "Prediction: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: 'str' object has no attribute 'content'\n",
      "Error running target function: 'str' object has no attribute 'content'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating answer for question: SW역량검증(TOPCIT) 정기평가 단체접수 대상자가 응시를 완료하면 어떤 혜택을 받을 수 있나요?\n",
      "Reference answer: 응시료 전액 지원과 함께 SW 마일리지 20점이 지급됩니다.\n",
      "Prediction: None\n",
      "Evaluating answer for question: SW역량검증(TOPCIT) 정기평가에 응시하지 않은 학생은 어떻게 되나요?\n",
      "Reference answer: 신청 후 불응시한 학생은 SW 마일리지에서 10점이 차감됩니다.\n",
      "Prediction: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 6471e184-6ccf-47d2-90ac-132ce0a5daa0: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 4a8f6f85-f120-4d24-bc39-51f8ed3ff41c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run aee6d5f5-fd43-459d-acaa-f5aafa443296: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 25782cd4-6f44-490e-b563-7a0054e57904: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 62a05a47-431a-489a-a4d6-a20f77df939c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating helpfulness for question: 2024년 제22회 SW역량검증(TOPCIT) 정기평가의 평가일시는 언제인가요?\n",
      "Prediction: None\n",
      "Evaluating helpfulness for question: SW역량검증(TOPCIT) 정기평가에 단체 접수한 학생이 반드시 해야 할 절차는 무엇인가요?\n",
      "Prediction: None\n",
      "Evaluating helpfulness for question: SW역량검증(TOPCIT) 정기평가 단체접수 신청은 어떻게 진행되나요?\n",
      "Prediction: None\n",
      "Evaluating helpfulness for question: SW역량검증(TOPCIT) 정기평가 단체접수 신청자는 어디서 시험을 보게 되나요?\n",
      "Prediction: None\n",
      "Evaluating helpfulness for question: SW역량검증(TOPCIT) 정기평가 관련 문의는 어디로 해야 하나요?\n",
      "Prediction: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run ad62d480-fd15-49e3-a840-5c3c4a39b5ee: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 5563b736-ea1b-43fa-90f9-2034ca2e23e4: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 158, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating helpfulness for question: SW역량검증(TOPCIT) 정기평가 단체접수 대상자가 응시를 완료하면 어떤 혜택을 받을 수 있나요?\n",
      "Prediction: None\n",
      "Evaluating helpfulness for question: SW역량검증(TOPCIT) 정기평가에 응시하지 않은 학생은 어떻게 되나요?\n",
      "Prediction: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 6471e184-6ccf-47d2-90ac-132ce0a5daa0: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run aee6d5f5-fd43-459d-acaa-f5aafa443296: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 4a8f6f85-f120-4d24-bc39-51f8ed3ff41c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 25782cd4-6f44-490e-b563-7a0054e57904: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 62a05a47-431a-489a-a4d6-a20f77df939c: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 5563b736-ea1b-43fa-90f9-2034ca2e23e4: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run ad62d480-fd15-49e3-a840-5c3c4a39b5ee: BadRequestError('Bad Request')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1325, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEESEOKHYUN\\AppData\\Local\\Temp\\ipykernel_9600\\350325493.py\", line 221, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 2879, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5093, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 277, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 777, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 624, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 846, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\langchain_upstage\\chat_models.py\", line 227, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LEESEOKHYUN\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Bad Request\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langsmith import Client\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain import hub\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create dataset in LangSmith\n",
    "example_inputs = [\n",
    "    (\"2024년 제22회 SW역량검증(TOPCIT) 정기평가의 평가일시는 언제인가요?\",\n",
    "     \"2024년 10월 12일 토요일 오전 9시 30분부터 12시까지입니다. 고사장 입실 완료 시간은 9시 10분입니다.\"),\n",
    "    (\"SW역량검증(TOPCIT) 정기평가에 단체 접수한 학생이 반드시 해야 할 절차는 무엇인가요?\",\n",
    "     \"(가) 구글 폼 신청과 (나) TOPCIT 홈페이지에서 신청자 정보등록을 모두 완료해야 시험에 응시할 수 있습니다.\"),\n",
    "    (\"SW역량검증(TOPCIT) 정기평가 단체접수의 등록기간은 언제인가요?\",\n",
    "     \"등록기간은 2024년 9월 12일(목)부터 9월 19일(목) 오후 3시까지입니다.\"),\n",
    "    (\"SW역량검증(TOPCIT) 정기평가 단체접수 대상자가 응시를 완료하면 어떤 혜택을 받을 수 있나요?\",\n",
    "     \"응시료 전액 지원과 함께 SW 마일리지 20점이 지급됩니다.\"),\n",
    "    (\"SW역량검증(TOPCIT) 정기평가에 응시하지 않은 학생은 어떻게 되나요?\",\n",
    "     \"신청 후 불응시한 학생은 SW 마일리지에서 10점이 차감됩니다.\"),\n",
    "    (\"SW역량검증(TOPCIT) 정기평가 단체접수 신청자는 어디서 시험을 보게 되나요?\",\n",
    "     \"단체접수용 시험장은 경북대학교 내 실습장으로 배정되며, 정확한 장소는 수험표 발급기간에 확인할 수 있습니다.\"),\n",
    "    (\"SW역량검증(TOPCIT) 정기평가 단체접수 신청은 어떻게 진행되나요?\",\n",
    "     \"구글 폼 링크를 통해 신청한 후, TOPCIT 홈페이지에서 신청자 정보를 등록해야 합니다.\"),\n",
    "    (\"SW역량검증(TOPCIT) 정기평가 관련 문의는 어디로 해야 하나요?\",\n",
    "     \"소프트웨어교육원(전화: 053-950-7670, 이메일: bk6722@knu.ac.kr)으로 문의할 수 있습니다.\"),\n",
    "]\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"TOPCIT_1\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name, description=\"Questions and answers about TOPCIT\",\n",
    ")\n",
    "for input_prompt, output_answer in example_inputs:\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs={\"answer\": output_answer},\n",
    "        metadata={\"source\": \"공지사항\"},\n",
    "        dataset_id=dataset.id,\n",
    "    )\n",
    "\n",
    "# Load docs\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&wr_id=28223\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"id\": [\"bo_v_con\", \"bo_v_title\"]},\n",
    "        )\n",
    "    )\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = UpstageEmbeddings(\n",
    "    model=\"solar-embedding-1-large\"\n",
    ")\n",
    "\n",
    "# Embed and store in Pinecone\n",
    "index_name = 'tax-index'\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "database = PineconeVectorStore.from_documents(splits, embeddings, index_name=index_name)\n",
    "\n",
    "retriever = database.as_retriever()\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"upstage-model\"):\n",
    "        self._retriever = retriever\n",
    "        self._client = ChatUpstage(model=model)\n",
    "        self._model = model\n",
    "\n",
    "    def retrieve_docs(self, question):\n",
    "        # Document search\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    def invoke_llm(self, question, docs):\n",
    "        # Call Upstage LLM\n",
    "        response = self._client.generate(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"당신은 공지사항의 내용을 정확히 알려주는 직원입니다. \"\n",
    "                               \"다음 문서들을 사용하여 사용자 질문에 대한 간결한 답변을 작성하십시오.\\n\\n\"\n",
    "                               f\"## Docs\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Debug response\n",
    "        print(\"Response:\", response)\n",
    "\n",
    "        # Extract answer from response\n",
    "        answer = response['choices'][0]['message']['content']\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"contexts\": [str(doc) for doc in docs],\n",
    "        }\n",
    "\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)\n",
    "\n",
    "def predict_rag_answer(example: dict):\n",
    "    \"\"\"답변만 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\"answer\": response[\"answer\"]}\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Context를 활용해서 hallucination을 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}\n",
    "\n",
    "# Grade prompt\n",
    "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")  # Upstage에서 제공하는 prompt\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Get question, ground truth answer, RAG chain answer\n",
    "    input_question = example.inputs.get(\"question\")\n",
    "    reference = example.outputs.get(\"answer\")\n",
    "    prediction = run.outputs.get(\"answer\")\n",
    "\n",
    "    # Debug information\n",
    "    print(f\"Evaluating answer for question: {input_question}\")\n",
    "    print(f\"Reference answer: {reference}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "\n",
    "    # Upstage grader\n",
    "    llm = ChatUpstage(model=\"upstage-model\")\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Run evaluator\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"correct_answer\": reference,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}\n",
    "\n",
    "# Prompt\n",
    "grade_prompt_hallucinations = hub.pull(\"langchain-ai/rag-answer-hallucination\")  # Upstage에서 제공하는 프롬프트\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for generation hallucination\n",
    "    \"\"\"\n",
    "\n",
    "    # RAG inputs\n",
    "    input_question = example.inputs.get(\"question\")\n",
    "    contexts = run.outputs.get(\"contexts\")\n",
    "\n",
    "    # RAG answer\n",
    "    prediction = run.outputs.get(\"answer\")\n",
    "\n",
    "    # Debug information\n",
    "    print(f\"Evaluating hallucinations for question: {input_question}\")\n",
    "    print(f\"Contexts: {contexts}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "\n",
    "    # Upstage grader\n",
    "    llm = ChatUpstage(model=\"upstage-model\")\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_hallucinations | llm\n",
    "\n",
    "    # Get score\n",
    "    score = answer_grader.invoke({\"documents\": contexts,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": score}\n",
    "\n",
    "# Grade prompt\n",
    "grade_prompt_answer_helpfulness = hub.pull(\"langchain-ai/rag-answer-helpfulness\")  # Upstage에서 제공하는 프롬프트\n",
    "\n",
    "def answer_helpfulness_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer helpfulness\n",
    "    \"\"\"\n",
    "\n",
    "    # Get question and RAG chain answer\n",
    "    input_question = example.inputs.get(\"question\")\n",
    "    prediction = run.outputs.get(\"answer\")\n",
    "\n",
    "    # Debug information\n",
    "    print(f\"Evaluating helpfulness for question: {input_question}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "\n",
    "    # Upstage grader\n",
    "    llm = ChatUpstage(model=\"upstage-model\")\n",
    "\n",
    "    # Structured prompt\n",
    "    answer_grader = grade_prompt_answer_helpfulness | llm\n",
    "\n",
    "    # Run evaluator\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_helpfulness_score\", \"score\": score}\n",
    "\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_evaluator, answer_helpfulness_evaluator],\n",
    "    experiment_prefix=\"topcit_evaluate\",\n",
    "    metadata={\"version\": \"topcit, upstage-model\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
